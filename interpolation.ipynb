{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95546e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import TypedDict\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from helpers.evals import evaluate_model_with_scaling\n",
    "from helpers.features import process_dataset\n",
    "from helpers.loaders import prepare_data_for_interpolation\n",
    "from helpers.models import FrequencyAwareNetwork\n",
    "from helpers.trainers import train_frequency_aware_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfd5de",
   "metadata": {},
   "source": [
    "### Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cdd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS = False\n",
    "VERBOSE = True\n",
    "\n",
    "DATASET_FILE_PATH = \"dataset.csv\"\n",
    "\n",
    "GRAPH_FOLDER = \"graphs\"\n",
    "MODELS = \"models\"\n",
    "PREDICTIONS = \"predictions\"\n",
    "SUBFOLDER = \"baseline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b872cd",
   "metadata": {},
   "source": [
    "### Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b215b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 18 frequency-related features and 13 other features\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_FILE_PATH)\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    voltage_scaler,\n",
    "    freq_scaler,\n",
    "    freq_idx,\n",
    "    other_idx,\n",
    ") = process_dataset(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91ca82",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b7f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(MODELS) / SUBFOLDER\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ba5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerTypes(str, Enum):\n",
    "    REDUCE_ON_PLATEAU = \"reduce_on_plateau\"\n",
    "    STEP = \"step\"\n",
    "    COSINE_ANNEALING = \"cosine_annealing\"\n",
    "    ONE_CYCLE = \"one_cycle\"\n",
    "    EXPONENTIAL = \"exponential\"\n",
    "    NONE = \"none\"\n",
    "\n",
    "\n",
    "class ActivationTypes(str, Enum):\n",
    "    GELU = \"gelu\"\n",
    "    RELU = \"relu\"\n",
    "    SILU = \"silu\"\n",
    "\n",
    "\n",
    "class Hyperparameters(TypedDict):\n",
    "    hidden_sizes: list[int]\n",
    "    dropout_rate: float\n",
    "    learning_rate: float\n",
    "    activation: ActivationTypes\n",
    "    lr_scheduler_type: SchedulerTypes\n",
    "    epochs: int\n",
    "    patience: int\n",
    "    batch_size: int\n",
    "    scale_y: bool\n",
    "\n",
    "\n",
    "class ModelDict(TypedDict):\n",
    "    model_name: str\n",
    "    labels: tuple[str, str]\n",
    "    hparams: Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1329a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "s11_params: Hyperparameters = {\n",
    "    \"hidden_sizes\": [256, 512, 1024, 512],\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 200,\n",
    "    \"patience\": 30,\n",
    "    \"lr_scheduler_type\": SchedulerTypes.REDUCE_ON_PLATEAU,\n",
    "    \"activation\": ActivationTypes.GELU,\n",
    "    \"scale_y\": False,\n",
    "}\n",
    "s12_params: Hyperparameters = {\n",
    "    \"hidden_sizes\": [384, 768, 1536, 768, 384],\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 300,\n",
    "    \"patience\": 40,\n",
    "    \"lr_scheduler_type\": SchedulerTypes.REDUCE_ON_PLATEAU,\n",
    "    \"activation\": ActivationTypes.GELU,\n",
    "    \"scale_y\": True,\n",
    "}\n",
    "\n",
    "s21_params: Hyperparameters = {\n",
    "    \"hidden_sizes\": [1024, 2048, 2048, 1024],\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 200,\n",
    "    \"patience\": 30,\n",
    "    \"lr_scheduler_type\": SchedulerTypes.REDUCE_ON_PLATEAU,\n",
    "    \"activation\": ActivationTypes.GELU,\n",
    "    \"scale_y\": False,\n",
    "}\n",
    "\n",
    "s22_params: Hyperparameters = {\n",
    "    \"hidden_sizes\": [1024, 1536, 2048, 1536, 1024],\n",
    "    \"learning_rate\": 0.002,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 200,\n",
    "    \"patience\": 30,\n",
    "    \"lr_scheduler_type\": SchedulerTypes.REDUCE_ON_PLATEAU,\n",
    "    \"activation\": ActivationTypes.GELU,\n",
    "    \"scale_y\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472001c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train: list[ModelDict] = [\n",
    "    {\n",
    "        \"model_name\": \"s11\",\n",
    "        \"labels\": (\"S_deemb(1,1)_real\", \"S_deemb(1,1)_imag\"),\n",
    "        \"hparams\": s11_params,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"s12\",\n",
    "        \"labels\": (\"S_deemb(1,2)_real\", \"S_deemb(1,2)_imag\"),\n",
    "        \"hparams\": s12_params,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"s21\",\n",
    "        \"labels\": (\"S_deemb(2,1)_real\", \"S_deemb(2,1)_imag\"),\n",
    "        \"hparams\": s21_params,\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"s22\",\n",
    "        \"labels\": (\"S_deemb(2,2)_real\", \"S_deemb(2,2)_imag\"),\n",
    "        \"hparams\": s22_params,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c72d7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training s11 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   8%|▊         | 15/200 [00:09<02:00,  1.54it/s, Epoch=15, Val Loss=0.007247, Best=0.006822, LR=0.001]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     31\u001b[39m optimizer = optim.Adam(\n\u001b[32m     32\u001b[39m     model.parameters(), lr=model_to_train[\u001b[33m\"\u001b[39m\u001b[33mhparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m criterion = nn.MSELoss()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m trained_model = \u001b[43mtrain_frequency_aware_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mY_test_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_to_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_to_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpatience\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_to_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr_scheduler_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m metrics = evaluate_model_with_scaling(\n\u001b[32m     49\u001b[39m     trained_model,\n\u001b[32m     50\u001b[39m     X_test_tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     y_scaler,\n\u001b[32m     55\u001b[39m )\n\u001b[32m     56\u001b[39m results[model_to_train[\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m]] = metrics\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml4rf/helpers/trainers.py:92\u001b[39m, in \u001b[36mtrain_frequency_aware_model\u001b[39m\u001b[34m(model, train_loader, X_test, Y_test, criterion, optimizer, device, epochs, patience, scheduler_str, tqdm_position, tqdm_disable, suffix, warmup_epochs, max_grad_norm)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# ✅ Gradient clipping\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_grad_norm\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m optimizer.step()\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# ✅ Step OneCycleLR scheduler per batch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py:38\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py:220\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    218\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    219\u001b[39m total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[43m_clip_grads_with_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py:38\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/nn/utils/clip_grad.py:165\u001b[39m, in \u001b[36m_clip_grads_with_norm_\u001b[39m\u001b[34m(parameters, max_norm, total_norm, foreach)\u001b[39m\n\u001b[32m    163\u001b[39m clip_coef_clamped = torch.clamp(clip_coef, \u001b[38;5;28mmax\u001b[39m=\u001b[32m1.0\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads.items():\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_has_foreach_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    166\u001b[39m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[32m    167\u001b[39m     ):\n\u001b[32m    168\u001b[39m         torch._foreach_mul_(device_grads, clip_coef_clamped.to(device))\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/utils/_foreach_utils.py:44\u001b[39m, in \u001b[36m_has_foreach_support\u001b[39m\u001b[34m(tensors, device)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_has_foreach_support\u001b[39m(tensors: \u001b[38;5;28mlist\u001b[39m[Tensor], device: torch.device) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_device_has_foreach_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01min\u001b[39;00m _foreach_supported_types \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/utils/_foreach_utils.py:40\u001b[39m, in \u001b[36m_device_has_foreach_support\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_device_has_foreach_support\u001b[39m(device: torch.device) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m device.type \u001b[38;5;129;01min\u001b[39;00m (_get_foreach_kernels_supported_devices() + [\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/venv/lib/python3.13/site-packages/torch/_jit_internal.py:101\u001b[39m, in \u001b[36mis_scripting\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m7\u001b[39m):\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = BroadcastingList1\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_scripting\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m \u001b[33;03m                return unsupported_linear_op(x)\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for model_to_train in models_to_train:\n",
    "    real_label, imag_label = model_to_train[\"labels\"]\n",
    "    label_pair = [real_label, imag_label]\n",
    "    y_train_pair = Y_train[label_pair]\n",
    "    y_test_pair = Y_test[label_pair]\n",
    "\n",
    "    print(f\"Training {model_to_train['model_name']} model\")\n",
    "\n",
    "    X_train_tensor, Y_train_tensor, X_test_tensor, Y_test_tensor, loader, y_scaler = (\n",
    "        prepare_data_for_interpolation(\n",
    "            X_train,\n",
    "            y_train_pair,\n",
    "            X_test,\n",
    "            y_test_pair,\n",
    "            batch_size=model_to_train[\"hparams\"][\"batch_size\"],\n",
    "            scale_y=model_to_train[\"hparams\"][\"scale_y\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model = FrequencyAwareNetwork(\n",
    "        len(freq_idx),\n",
    "        len(other_idx),\n",
    "        model_to_train[\"hparams\"][\"hidden_sizes\"],\n",
    "        model_to_train[\"hparams\"][\"dropout_rate\"],\n",
    "        model_to_train[\"hparams\"][\"activation\"],\n",
    "    )\n",
    "    model.set_feature_indices(freq_idx, other_idx)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=model_to_train[\"hparams\"][\"learning_rate\"]\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    trained_model = train_frequency_aware_model(\n",
    "        model,\n",
    "        loader,\n",
    "        X_test_tensor,\n",
    "        Y_test_tensor,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epochs=model_to_train[\"hparams\"][\"epochs\"],\n",
    "        patience=model_to_train[\"hparams\"][\"patience\"],\n",
    "        scheduler_str=model_to_train[\"hparams\"][\"lr_scheduler_type\"],\n",
    "    )\n",
    "\n",
    "    metrics = evaluate_model_with_scaling(\n",
    "        trained_model,\n",
    "        X_test_tensor,\n",
    "        Y_test,\n",
    "        label_pair,\n",
    "        device,\n",
    "        y_scaler,\n",
    "    )\n",
    "    results[model_to_train[\"model_name\"]] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c2dae",
   "metadata": {},
   "source": [
    "### Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_to_train in models_to_train:\n",
    "    model_name = model_to_train[\"model_name\"]\n",
    "\n",
    "    metrics, avg_metrics, predictions_original = results[model_name]\n",
    "\n",
    "    print(\"--\" * 20)\n",
    "    print(\"--\" * 20)\n",
    "    print(f\"Performance metrics for {model_name}:\")\n",
    "    for component, metric in metrics.items():\n",
    "        print(f\"\\n\\t{component}:\")\n",
    "        print(f\"\\tRMSE: {metric['rmse']:.6f}\")\n",
    "        print(f\"\\tR²: {metric['r2']:.6f}\")\n",
    "        print(f\"\\tMAE: {metric['mae']:.6f}\")\n",
    "        if \"smape\" in metric:\n",
    "            print(f\"\\tSMAPE: {metric['smape']:.2f}%\")\n",
    "        else:\n",
    "            print(f\"\\tMAPE: {metric['mape']:.2f}%\")\n",
    "\n",
    "    print(f\"\\nAverage metrics for {model_name}:\")\n",
    "    print(f\"\\n\\tR²: {avg_metrics['r2']:.6f}\")\n",
    "    print(f\"\\tRMSE: {avg_metrics['rmse']:.6f}\")\n",
    "    print(f\"\\tMAE: {avg_metrics['mae']:.6f}\")\n",
    "    if \"smape\" in avg_metrics:\n",
    "        print(f\"\\tSMAPE: {avg_metrics['smape']:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\tMAPE: {avg_metrics['mape']:.2f}%\")\n",
    "\n",
    "print(\"--\" * 20)\n",
    "print(\"--\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
