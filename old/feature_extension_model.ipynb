{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6025795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f84c66",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS = False\n",
    "GRAPH_FOLDER = \"graphs\"\n",
    "MODELS = \"models\"\n",
    "PREDICTIONS = \"predictions\"\n",
    "SUBFOLDER = \"feature_extraction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7658e2",
   "metadata": {},
   "source": [
    "### Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to identify frequency-related features\n",
    "def identify_frequency_features(X_columns):\n",
    "    \"\"\"Identify frequency-related features in the dataset.\"\"\"\n",
    "    freq_features = [\n",
    "        i\n",
    "        for i, col in enumerate(X_columns)\n",
    "        if \"freq\" in col.lower() or \"band\" in col.lower()\n",
    "    ]\n",
    "    other_features = [i for i in range(len(X_columns)) if i not in freq_features]\n",
    "\n",
    "    print(\n",
    "        f\"Identified {len(freq_features)} frequency-related features and {len(other_features)} other features\"\n",
    "    )\n",
    "    return freq_features, other_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "file_path = \"dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "target_cols = [\"gm\", \"Cmu\", \"Cpi\", \"Zout_real\", \"Zin_real\", \"Zout_imag\", \"Zin_imag\"]\n",
    "nan_heavy_cols = [\"MAG\", \"MSG\"]  # Columns with too many NaN values TODO: investigate\n",
    "exclude_columns = (\n",
    "    target_cols\n",
    "    + nan_heavy_cols\n",
    "    + [\n",
    "        \"TIMEDATE\",\n",
    "        \"OPERATOR\",\n",
    "        \"REMARKS\",\n",
    "        \"TECHNO\",\n",
    "        \"LOT\",\n",
    "        \"WAFER\",\n",
    "        \"CHIP\",\n",
    "        \"MODULE\",\n",
    "        \"DEV_NAME\",\n",
    "        \"S(1,1)_real\",\n",
    "        \"S(1,1)_imag\",\n",
    "        \"S(1,2)_real\",\n",
    "        \"S(1,2)_imag\",\n",
    "        \"S(2,1)_real\",\n",
    "        \"S(2,1)_imag\",\n",
    "        \"S(2,2)_real\",\n",
    "        \"S(2,2)_imag\",\n",
    "        \"S_deemb(1,1)_real\",\n",
    "        \"S_deemb(1,1)_imag\",\n",
    "        \"S_deemb(1,2)_real\",\n",
    "        \"S_deemb(1,2)_imag\",\n",
    "        \"S_deemb(2,1)_real\",\n",
    "        \"S_deemb(2,1)_imag\",\n",
    "        \"S_deemb(2,2)_real\",\n",
    "        \"S_deemb(2,2)_imag\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "all_cols = df.columns.tolist()\n",
    "X_cols = [\n",
    "    col\n",
    "    for col in all_cols\n",
    "    if col not in exclude_columns and pd.api.types.is_numeric_dtype(df[col])\n",
    "]\n",
    "\n",
    "# Split input and targets\n",
    "X = df[X_cols]\n",
    "Y = df[target_cols]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalize X (standardization)\n",
    "x_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "X_test_scaled = x_scaler.transform(X_test)\n",
    "\n",
    "freq_idx, other_idx = identify_frequency_features(X_train.columns)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "Y_train_tensor = torch.tensor(Y_train.values, dtype=torch.float32)\n",
    "Y_test_tensor = torch.tensor(Y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS:\n",
    "    print(df.columns)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2357763",
   "metadata": {},
   "source": [
    "### Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance():\n",
    "    # Target variables\n",
    "    targets = [\"gm\", \"Cpi\", \"Cmu\", \"Zin_real\", \"Zin_imag\", \"Zout_real\", \"Zout_imag\"]\n",
    "\n",
    "    # Drop non-numeric or identifier columns that shouldn't be features\n",
    "    exclude_columns = [\n",
    "        \"TIMEDATE\",\n",
    "        \"OPERATOR\",\n",
    "        \"REMARKS\",\n",
    "        \"TECHNO\",\n",
    "        \"LOT\",\n",
    "        \"WAFER\",\n",
    "        \"CHIP\",\n",
    "        \"MODULE\",\n",
    "        \"DEV_NAME\",\n",
    "        \"S(1,1)_real\",\n",
    "        \"S(1,1)_imag\",\n",
    "        \"S(1,2)_real\",\n",
    "        \"S(1,2)_imag\",\n",
    "        \"S(2,1)_real\",\n",
    "        \"S(2,1)_imag\",\n",
    "        \"S(2,2)_real\",\n",
    "        \"S(2,2)_imag\",\n",
    "        \"S_deemb(1,1)_real\",\n",
    "        \"S_deemb(1,1)_imag\",\n",
    "        \"S_deemb(1,2)_real\",\n",
    "        \"S_deemb(1,2)_imag\",\n",
    "        \"S_deemb(2,1)_real\",\n",
    "        \"S_deemb(2,1)_imag\",\n",
    "        \"S_deemb(2,2)_real\",\n",
    "        \"S_deemb(2,2)_imag\",\n",
    "    ]\n",
    "    all_numeric = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if col not in exclude_columns and pd.api.types.is_numeric_dtype(df[col])\n",
    "    ]\n",
    "\n",
    "    # Directory to save plots\n",
    "    output_dir = Path(GRAPH_FOLDER) / SUBFOLDER\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Prepare data (remove rows with missing target values)\n",
    "    df_clean = df.dropna(subset=targets)\n",
    "    X_raw = df_clean[all_numeric]\n",
    "\n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_imputed = imputer.fit_transform(X_raw)\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    # Reconstruct feature names after transformation\n",
    "    X_df = pd.DataFrame(X_scaled, columns=all_numeric)\n",
    "\n",
    "    # Loop over each target, using all other numeric columns (including other targets) as features\n",
    "    for target in targets:\n",
    "        print(f\"\\nüîç Feature Importance for Target: {target}\")\n",
    "\n",
    "        feature_cols = [col for col in X_df.columns if col != target]\n",
    "        X_target = X_df[feature_cols]\n",
    "        y_target = X_df[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_target, y_target, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Train XGBoost model\n",
    "        model = xgb.XGBRegressor(\n",
    "            tree_method=\"gpu_hist\",\n",
    "            predictor=\"gpu_predictor\",\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        sorted_idx = importances.argsort()[::-1]\n",
    "        sorted_features = [feature_cols[i] for i in sorted_idx]\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(range(len(sorted_idx)), importances[sorted_idx], align=\"center\")\n",
    "        plt.yticks(range(len(sorted_idx)), sorted_features)\n",
    "        plt.xlabel(\"Feature Importance\")\n",
    "        plt.title(f\"Feature Importance for Predicting {target}\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        file_path = os.path.join(output_dir, f\"{target}_importance.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if ANALYSIS:\n",
    "    get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e1bbe",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a71919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "chain_targets = [\n",
    "    \"gm\",\n",
    "    \"Cmu\",\n",
    "    \"Cpi\",\n",
    "    \"Zout_real\",\n",
    "    \"Zin_real\",\n",
    "    \"Zout_imag\",\n",
    "    \"Zin_imag\",\n",
    "]  # Derived from analysis\n",
    "batch_size = 2048\n",
    "num_workers = 12\n",
    "pin_memory = False\n",
    "persistent_workers = True\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if num_workers > 0:\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "    persistent_workers = True\n",
    "\n",
    "if device != \"cpu\":\n",
    "    pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65268c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Frequency-Aware Neural Network\n",
    "class FrequencyAwareNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        freq_features,\n",
    "        other_features,\n",
    "        # hidden_sizes=[128, 256, 512],\n",
    "        hidden_sizes=[64, 128, 256],\n",
    "        dropout_rate=0.2,\n",
    "        activation=\"silu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.freq_indices = None\n",
    "        self.other_indices = None\n",
    "        act_fn = {\"silu\": nn.SiLU(), \"relu\": nn.ReLU(), \"gelu\": nn.GELU()}[activation]\n",
    "\n",
    "        def build_branch(in_size):\n",
    "            layers = []\n",
    "            for h in hidden_sizes[:2]:\n",
    "                layers += [\n",
    "                    nn.Linear(in_size, h),\n",
    "                    act_fn,\n",
    "                    nn.BatchNorm1d(h),\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                ]\n",
    "                in_size = h\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.freq_branch = build_branch(freq_features)\n",
    "        self.other_branch = build_branch(other_features)\n",
    "\n",
    "        comb_input = hidden_sizes[1] * 2\n",
    "        combined = []\n",
    "        for h in hidden_sizes[2:]:\n",
    "            combined += [\n",
    "                nn.Linear(comb_input, h),\n",
    "                act_fn,\n",
    "                nn.BatchNorm1d(h),\n",
    "                nn.Dropout(dropout_rate),\n",
    "            ]\n",
    "            comb_input = h\n",
    "        combined.append(nn.Linear(comb_input, 1))\n",
    "        self.combined = nn.Sequential(*combined)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.freq_indices is None or self.other_indices is None:\n",
    "            raise ValueError(\"Feature indices not set.\")\n",
    "        f = x[:, self.freq_indices]\n",
    "        o = x[:, self.other_indices]\n",
    "        return self.combined(\n",
    "            torch.cat([self.freq_branch(f), self.other_branch(o)], dim=1)\n",
    "        )\n",
    "\n",
    "    def set_feature_indices(self, freq_idx, other_idx):\n",
    "        self.freq_indices = freq_idx\n",
    "        self.other_indices = other_idx\n",
    "\n",
    "\n",
    "# Define Chained Predictor\n",
    "class ChainedPredictor(nn.Module):\n",
    "    def __init__(\n",
    "        self, model_fn, chain_order, freq_size, base_other_size, device=\"cuda\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleDict()\n",
    "        self.chain_order = chain_order\n",
    "        self.device = device\n",
    "        self.feature_indices = {}\n",
    "        self.freq_size = freq_size\n",
    "        self.base_other_size = base_other_size\n",
    "\n",
    "        for i, name in enumerate(chain_order):\n",
    "            extra_inputs = i  # each new prediction is appended to inputs\n",
    "            self.models[name] = model_fn(freq_size, base_other_size + extra_inputs).to(\n",
    "                device\n",
    "            )\n",
    "\n",
    "    def set_feature_indices(self, name, freq_idx, other_idx):\n",
    "        self.models[name].set_feature_indices(freq_idx, other_idx)\n",
    "        self.feature_indices[name] = (freq_idx, other_idx)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = {}\n",
    "        x = x.to(self.device)\n",
    "        for name in self.chain_order:\n",
    "            out = self.models[name](x)\n",
    "            outputs[name] = out\n",
    "            x = torch.cat([x, out], dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d143c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking\n",
    "stage_predictions_train = {}\n",
    "stage_predictions_test = {}\n",
    "trained_models = {}\n",
    "target_scalers = {}\n",
    "\n",
    "# Input tensors\n",
    "X_train_chain = X_train_tensor.clone().cuda()\n",
    "X_test_chain = X_test_tensor.clone().cuda()\n",
    "\n",
    "# Directory to save models\n",
    "model_dir = Path(MODELS) / SUBFOLDER\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, target in enumerate(chain_targets):\n",
    "    print(f\"\\nüîÅ Training model for: {target} (Stage {i + 1}/{len(chain_targets)})\")\n",
    "\n",
    "    # Get and scale target values\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train_np = Y_train_tensor[:, i].cpu().numpy().reshape(-1, 1)\n",
    "    y_test_np = Y_test_tensor[:, i].cpu().numpy().reshape(-1, 1)\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train_np)\n",
    "    y_test_scaled = y_scaler.transform(y_test_np)\n",
    "    target_train = torch.FloatTensor(y_train_scaled).to(device)\n",
    "    target_test = torch.FloatTensor(y_test_scaled).to(device)\n",
    "    target_scalers[target] = y_scaler\n",
    "\n",
    "    # Create model\n",
    "    model = FrequencyAwareNetwork(\n",
    "        freq_features=len(freq_idx),\n",
    "        other_features=X_train_chain.shape[1] - len(freq_idx),\n",
    "        hidden_sizes=[64, 128, 256],\n",
    "        dropout_rate=0.2,\n",
    "        activation=\"silu\",\n",
    "    ).to(device)\n",
    "\n",
    "    model.set_feature_indices(\n",
    "        freq_idx=freq_idx,\n",
    "        other_idx=[j for j in range(X_train_chain.shape[1]) if j not in freq_idx],\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_chain, target_train)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=persistent_workers,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_model_state = None\n",
    "    best_loss = float(\"inf\")\n",
    "    patience = 15\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.cuda(non_blocking=True)\n",
    "            yb = yb.cuda(non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(\"‚ö†Ô∏è Skipping batch due to NaN loss.\")\n",
    "                continue\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            del xb, yb\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        avg_loss = running_loss / max(len(train_loader), 1)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_test_chain)\n",
    "            val_loss = criterion(val_pred, target_test).item()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1:3d}: Train Loss = {avg_loss:.5f} | Val Loss = {val_loss:.5f}\"\n",
    "        )\n",
    "\n",
    "        # Early stopping logic\n",
    "        if not torch.isnan(torch.tensor(val_loss)) and val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"üõë Early stopping.\")\n",
    "                break\n",
    "\n",
    "    # Load best model state\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No best state found, using last epoch weights.\")\n",
    "\n",
    "    # Save model and scaler\n",
    "    trained_models[target] = model\n",
    "    model_path = model_dir / f\"{target}_model.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"‚úÖ Saved best model for {target} to {model_path}\")\n",
    "\n",
    "    # Predict for next stage\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_pred = model(X_train_chain)\n",
    "        test_pred = model(X_test_chain)\n",
    "\n",
    "    stage_predictions_train[target] = train_pred\n",
    "    stage_predictions_test[target] = test_pred\n",
    "\n",
    "    # Chain: append predictions to input for next stage\n",
    "    X_train_chain = torch.cat([X_train_chain, train_pred], dim=1)\n",
    "    X_test_chain = torch.cat([X_test_chain, test_pred], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8382912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.max_memory_allocated() / 1e6, \"MB used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "predictions_dir = Path(PREDICTIONS) / SUBFOLDER\n",
    "predictions_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_pred_df = pd.DataFrame(\n",
    "    {\n",
    "        target: preds.squeeze().detach().cpu().numpy()\n",
    "        for target, preds in stage_predictions_train.items()\n",
    "    }\n",
    ")\n",
    "train_pred_df.to_csv(predictions_dir / \"train_predictions.csv\", index=False)\n",
    "test_pred_df = pd.DataFrame(\n",
    "    {\n",
    "        target: preds.squeeze().detach().cpu().numpy()\n",
    "        for target, preds in stage_predictions_test.items()\n",
    "    }\n",
    ")\n",
    "test_pred_df.to_csv(predictions_dir / \"test_predictions.csv\", index=False)\n",
    "print(\"‚úÖ Predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d17750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate and load a trained model\n",
    "# loaded_model = FrequencyAwareNetwork(freq_features=len(freq_idx), other_features=base_other_size + i)\n",
    "# loaded_model.set_feature_indices(freq_idx, other_idx)\n",
    "# loaded_model.load_state_dict(torch.load(\"models/feature_extraction/Zout_real_model.pt\"))\n",
    "# loaded_model.to(\"cuda\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
